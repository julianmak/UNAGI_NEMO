#!/bin/bash

# NOTE: Lines starting with "#SBATCH" are valid SLURM commands or statements,
#       while those starting with "#" and "##SBATCH" are comments.  Uncomment
#       "##SBATCH" line means to remove one # and start with #SBATCH to be a
#       SLURM command or statement.

#===============================================================
# DEFINE SOME JUNK FOR THE SUBMISSION (??? make this more flexible with e.g. queues?)
#===============================================================

#SBATCH -J eke25            # job name 
#SBATCH -o stdouterr_%j     # output and error file name
#SBATCH -n 40               # total number of mpi tasks requested
#SBATCH -N 1                # total number of nodes requested
#SBATCH -p cpu              # queue (partition) -- standard, development, etc.
##SBATCH -A oces
#SBATCH -t 72:00:00         # maximum runtime
#SBATCH -x hhnode-ib-[201-228] # avoid some nodes

##SBATCH --mail-type=begin        # send email when job begins
##SBATCH --mail-type=end          # send email when job ends
##SBATCH --mail-type=fail         # send email if job fails
##SBATCH --mail-user=jclmak@ust.hk

# Setup runtime environment if necessary
# For example, setup MPI environment
module load openmpi3
python --version

which mpirun

# just make sure the environment really is off otherwise it seems to fail to load the environment here
source /opt/ohpc/pub/apps/anaconda3/bin/activate
source /opt/ohpc/pub/apps/anaconda3/bin/activate py38
python --version
# or you can source ~/.bashrc or ~/.bash_profile

which mpirun

#===============================================================
# LAUNCH JOB
#===============================================================

echo " _ __   ___ _ __ ___   ___         "
echo "| '_ \ / _ \ '_ ' _ \ / _ \        "
echo "| | | |  __/ | | | | | (_) |       "
echo "|_| |_|\___|_| |_| |_|\___/  v3.7  "

echo "OK: ...and here is Christopher doing some calculations for you......"
echo "                  ,-.____,-.          "
echo "                  /   ..   \          "
echo "                 /_        _\         "
echo "                |'o'      'o'|        "
echo "               / ____________ \       "
echo "             , ,'    '--'    '. .     "
echo "            _| |              | |_    "
echo "          /  ' '              ' '  \  "
echo "         (    ',',__________.','    ) "
echo "          \_    ' ._______, '     _/  "
echo "             |                  |     "
echo "             |    ,-.    ,-.    |     "
echo "              \      ).,(      /      "
echo "         gpyy   \___/    \___/        "

# Go to the job submission directory and run your application

# EXP_R025

for folder in {tau200x,tau300x,tau400x}; do
  /opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/bin/mpirun -n 1 python gen_ekezint_tave.py /scratch/PI/jclmak/data/users/julian/NEMO/UNAGI/nemo4.0.5/EXP_R025/split_100km/alp0060_lam80/${folder}/ANALYSIS/ "*MOC_U*" "*MOC_V*"
  /opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/bin/mpirun -n 1 python gen_epezint_tave.py /scratch/PI/jclmak/data/users/julian/NEMO/UNAGI/nemo4.0.5/EXP_R025/split_100km/alp0060_lam80/${folder}/ANALYSIS/ "*isodep_tave*" --sigma_var "sigma" --file_out "epe_zint_tave_full.nc"
done

#for folder in {alp0060,alp0060_lam90,alp0060_lam80}; do
#  export DATA_DIR=/scratch/PI/jclmak/data/users/julian/NEMO/UNAGI/nemo4.0.5/EXP_R025/no_split/${folder}/tau100x/ANALYSIS/
#  /opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/bin/mpirun -n 1 python gen_ekezint_tave.py ${DATA_DIR} "*MOC_U*" "*MOC_V*"
#  /opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/bin/mpirun -n 1 python gen_epezint_tave.py ${DATA_DIR} "*isodep_tave*" --sigma_var "sigma" --file_out "epe_zint_tave_full.nc"
#done

wait

echo "Done!"
